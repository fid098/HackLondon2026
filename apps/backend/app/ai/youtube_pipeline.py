"""
youtube_pipeline.py — 3-agent AI-content detection pipeline for YouTube videos.

The pipeline answers one question: "Was this YouTube video created by AI?"

Architecture:

  Step 0 — Parallel pre-analysis:
    a. Thumbnail deepfake scan  — is the thumbnail AI-generated?
    b. Channel credibility search — Serper search for channel reputation / AI farm signals

  Step 1 — Agent A (Defender, parallel with Agent B):
    Builds the strongest honest case that the content is HUMAN-CREATED.
    Looks for: natural speech patterns, cited sources, personal expertise, channel identity.

  Step 2 — Agent B (Prosecutor, parallel with Agent A):
    Builds the strongest honest case that the content is AI-GENERATED.
    Looks for: generic phrasing, template titles, no citations, TTS caption patterns,
    faceless channel, AI thumbnail.

  Step 3 — Judge:
    Weighs both arguments + thumbnail AI score + channel search evidence.
    Issues verdict: AI_GENERATED / HUMAN_CREATED / UNCERTAIN
    with confidence 0–100 and ai_indicators / human_indicators lists.

In mock mode all steps return realistic canned responses. In real mode all Gemini
calls use the actual transcript + metadata — no truncated previews.
"""

import asyncio
import json
import logging
import re
from dataclasses import dataclass, field

from app.ai.deepfake_pipeline import DeepfakeResult, deepfake_pipeline
from app.ai.gemini_client import gemini_client
from app.ai.serper_adapter import serper_adapter
from app.services.content_extractor import YouTubeData

logger = logging.getLogger(__name__)


# ── Data classes ──────────────────────────────────────────────────────────────

@dataclass
class YouTubeResult:
    video_id:            str
    title:               str
    channel:             str
    verdict:             str    # AI_GENERATED | HUMAN_CREATED | UNCERTAIN
    confidence:          int    # 0–100
    summary:             str
    ai_indicators:       list[str] = field(default_factory=list)
    human_indicators:    list[str] = field(default_factory=list)
    thumbnail_is_ai:     bool  = False
    thumbnail_confidence: float = 0.0
    defender_argument:   str  = ""
    prosecutor_argument: str  = ""
    judge_reasoning:     str  = ""
    has_transcript:      bool = False


# ── Prompts ───────────────────────────────────────────────────────────────────

_DEFENDER_PROMPT = """\
You are Agent A — Content Authenticity Defender. Your mission is to build the strongest
HONEST, EVIDENCE-BACKED case that the following YouTube video was CREATED BY A HUMAN.

VIDEO METADATA
──────────────
Title:       {title}
Channel:     {channel}
Description: {description}
Transcript available: {has_transcript}

TRANSCRIPT (excerpt):
{transcript}

THUMBNAIL ANALYSIS:
  AI manipulation score: {thumbnail_score}/1.0
  Summary: {thumbnail_summary}

CHANNEL CREDIBILITY SEARCH:
{search_results}

─── YOUR INSTRUCTIONS ───────────────────────────────────────────────────────────────────
1. Look for genuine HUMAN EXPERTISE MARKERS: domain-specific knowledge, personal anecdotes,
   corrections mid-sentence, references to real events the speaker witnessed.

2. Look for NATURAL SPEECH PATTERNS in the transcript: disfluencies, filler words,
   topic tangents, emotional variation — all are difficult for AI to replicate authentically.

3. Look for VERIFIED CITATIONS: named sources, dates, specific statistics with attribution.

4. Look for CHANNEL CREDIBILITY: consistent identity, history, thematic depth.

5. If thumbnail AI score is LOW (< 0.3), note this as supporting evidence for genuine content.

6. HONESTY: if evidence is weak, acknowledge it. Do not manufacture human signals.

─── FORMAT ──────────────────────────────────────────────────────────────────────────────
ARGUMENT: [2–3 paragraphs. Be specific about evidence found in the transcript/metadata.]

POINTS:
- [human creation indicator with evidence from transcript/metadata]
- [human creation indicator]
- [human creation indicator]

SOURCE QUALITY: [HIGH / MEDIUM / LOW]"""


_PROSECUTOR_PROMPT = """\
You are Agent B — AI Content Prosecutor. Your mission is to build the strongest
HONEST, EVIDENCE-BACKED case that the following YouTube video was GENERATED BY AI
(AI-written script, AI voice narration, AI-generated visuals, or a combination).

VIDEO METADATA
──────────────
Title:       {title}
Channel:     {channel}
Description: {description}
Transcript available: {has_transcript}

TRANSCRIPT (excerpt):
{transcript}

THUMBNAIL ANALYSIS:
  AI manipulation score: {thumbnail_score}/1.0
  Summary: {thumbnail_summary}

─── YOUR INSTRUCTIONS ───────────────────────────────────────────────────────────────────
1. Look for AI WRITING PATTERNS: consistent sentence length, lack of contractions,
   absence of filler words, unnaturally uniform paragraph structure.

2. Look for CONTENT FARM SIGNALS:
   - Title follows template: "X Things About Y" / "The Truth About Z" / superlative + generic noun
   - Faceless channel with stock imagery or AI-generated art
   - Description is keyword-stuffed with no personal voice
   - No citations, no linked sources, no external references

3. Assess THUMBNAIL AI SCORE: if ≥ 0.6, this is a strong signal of AI generation.

4. Look for TTS CAPTION PATTERNS: AI voiceover often produces captions with
   perfectly uniform sentence lengths, no interrupted sentences, no breath pauses.

5. No transcript available (has_transcript = false): faceless AI channels frequently
   disable captions to hide TTS fingerprints.

6. HONESTY: if evidence is genuinely weak, acknowledge it. Label SOURCE QUALITY: LOW.

─── FORMAT ──────────────────────────────────────────────────────────────────────────────
ARGUMENT: [2–3 paragraphs. Be specific about patterns found in the transcript/metadata.]

POINTS:
- [AI generation indicator with evidence]
- [AI generation indicator]
- [AI generation indicator]

SOURCE QUALITY: [HIGH / MEDIUM / LOW]"""


_JUDGE_PROMPT = """\
You are the Judge — AI Content Verifier. Determine whether this YouTube video was
created by a HUMAN or generated by AI. You are NOT fact-checking the claims;
you are assessing the AUTHENTICITY of the content creation process.

VIDEO: {title}
CHANNEL: {channel}

AGENT A (Defender — argues HUMAN-CREATED):
{defender_argument}

AGENT B (Prosecutor — argues AI-GENERATED):
{prosecutor_argument}

THUMBNAIL AI SCORE: {thumbnail_score}/1.0 → {thumbnail_verdict}
TRANSCRIPT AVAILABLE: {has_transcript}

─── EVALUATION RULES ────────────────────────────────────────────────────────────────────
1. Thumbnail AI score ≥ 0.70 = strong AI signal — weight heavily.
2. Multiple AI writing pattern indicators from Agent B + no counter from Agent A = AI_GENERATED.
3. No transcript (captions disabled) + faceless channel + template title = suspicious.
4. Specific citations, personal anecdotes, domain expertise = strong human signals.
5. UNCERTAIN is appropriate when signals are genuinely mixed (don't force a verdict).

─── VERDICTS ─────────────────────────────────────────────────────────────────────────────
AI_GENERATED  — Strong evidence of AI script/voice/generation. Confidence ≥ 65.
HUMAN_CREATED — Strong evidence of genuine human creation. Confidence ≥ 65.
UNCERTAIN     — Mixed signals or insufficient evidence for a confident verdict.

─── CONFIDENCE GUIDE ────────────────────────────────────────────────────────────────────
85–100: Multiple strong, independent AI or human signals
65–84 : Clear majority of signals pointing one way
45–64 : Mixed evidence; some signals each side
0–44  : Very little evidence; largely inconclusive

Respond with valid JSON only:
{{
  "verdict": "AI_GENERATED|HUMAN_CREATED|UNCERTAIN",
  "confidence": <0-100>,
  "summary": "2 sentences explaining the verdict",
  "ai_indicators": ["specific indicator 1", "specific indicator 2"],
  "human_indicators": ["specific indicator 1"],
  "reasoning": "3-4 sentences of detailed reasoning citing both agents and thumbnail data"
}}"""


# ── Parsing helpers ────────────────────────────────────────────────────────────

def _parse_argument(text: str) -> tuple[str, list[str]]:
    """Extract ARGUMENT section and POINTS bullets."""
    argument = text
    points: list[str] = []

    arg_m = re.search(r"ARGUMENT:\s*(.*?)(?=POINTS:|SOURCE QUALITY:|$)", text, re.DOTALL | re.IGNORECASE)
    pts_m = re.search(r"POINTS:\s*(.*?)(?=SOURCE QUALITY:|$)", text, re.DOTALL | re.IGNORECASE)

    if arg_m:
        argument = arg_m.group(1).strip()
    if pts_m:
        raw = pts_m.group(1).strip()
        points = [p.lstrip("- •").strip() for p in raw.splitlines() if p.strip().startswith("-")]

    return argument, points


def _parse_judge(text: str) -> dict:
    m = re.search(r"\{[\s\S]*\}", text)
    if m:
        try:
            return json.loads(m.group())
        except json.JSONDecodeError:
            pass
    upper = text.upper()
    for v in ("AI_GENERATED", "HUMAN_CREATED", "UNCERTAIN"):
        if v in upper:
            return {"verdict": v, "confidence": 50, "summary": text[:200],
                    "ai_indicators": [], "human_indicators": [], "reasoning": text}
    return {"verdict": "UNCERTAIN", "confidence": 30, "summary": "Unable to parse verdict.",
            "ai_indicators": [], "human_indicators": [], "reasoning": text}


def _fmt_search(results: list[dict]) -> str:
    if not results:
        return "No search results available."
    lines = []
    for i, r in enumerate(results[:4], 1):
        lines.append(f"[{i}] {r.get('title', '')} — {r.get('snippet', '')[:150]}")
    return "\n".join(lines)


async def _safe_thumbnail_analysis(yt_data: YouTubeData) -> DeepfakeResult | None:
    """Run thumbnail deepfake analysis; return None if no thumbnail available."""
    if not yt_data.thumbnail_b64:
        return None
    try:
        return await deepfake_pipeline.run_image(yt_data.thumbnail_b64, "image/jpeg")
    except Exception as exc:
        logger.warning("Thumbnail deepfake analysis failed: %s", exc)
        return None


# ── Pipeline ──────────────────────────────────────────────────────────────────

class YouTubePipeline:
    """
    Orchestrates the 3-agent AI-content detection debate for a YouTube video.

    Input:  YouTubeData (transcript + metadata + thumbnail_b64)
    Output: YouTubeResult (verdict, confidence, indicators, debate transcript)
    """

    async def run(self, yt_data: YouTubeData) -> YouTubeResult:
        logger.info(
            "Starting YouTube AI-detection pipeline for: %.80s (channel: %s)",
            yt_data.title, yt_data.channel,
        )

        # ── Step 0: Parallel pre-analysis ─────────────────────────────────
        thumb_task   = _safe_thumbnail_analysis(yt_data)
        search_query = f'"{yt_data.channel}" YouTube channel AI generated OR faceless OR bot'
        search_task  = serper_adapter.search(search_query[:200])

        thumb_result, search_raw = await asyncio.gather(thumb_task, search_task)

        # Thumbnail summary for prompts
        if thumb_result:
            thumb_score   = round(thumb_result.confidence, 2)
            thumb_summary = thumb_result.reasoning[:200]
            thumb_verdict = "AI-generated thumbnail" if thumb_result.is_fake else "Appears genuine"
        else:
            thumb_score   = 0.0
            thumb_summary = "Thumbnail not available for analysis."
            thumb_verdict = "No thumbnail data"

        search_text = _fmt_search(search_raw)

        # ── Step 1 & 2: Defender and Prosecutor in parallel ────────────────
        transcript_excerpt = yt_data.transcript[:3000] or "[No transcript available]"

        defender_prompt = _DEFENDER_PROMPT.format(
            title=yt_data.title or "Unknown",
            channel=yt_data.channel or "Unknown",
            description=yt_data.description[:300] or "No description.",
            has_transcript=str(yt_data.has_transcript),
            transcript=transcript_excerpt,
            thumbnail_score=thumb_score,
            thumbnail_summary=thumb_summary,
            search_results=search_text,
        )
        prosecutor_prompt = _PROSECUTOR_PROMPT.format(
            title=yt_data.title or "Unknown",
            channel=yt_data.channel or "Unknown",
            description=yt_data.description[:300] or "No description.",
            has_transcript=str(yt_data.has_transcript),
            transcript=transcript_excerpt,
            thumbnail_score=thumb_score,
            thumbnail_summary=thumb_summary,
        )

        defender_raw, prosecutor_raw = await asyncio.gather(
            gemini_client.generate_with_pro(defender_prompt, response_key="youtube_defender"),
            gemini_client.generate_with_pro(prosecutor_prompt, response_key="youtube_prosecutor"),
        )

        defender_argument, _ = _parse_argument(defender_raw)
        prosecutor_argument, _ = _parse_argument(prosecutor_raw)

        # ── Step 3: Judge ──────────────────────────────────────────────────
        judge_prompt = _JUDGE_PROMPT.format(
            title=yt_data.title or "Unknown",
            channel=yt_data.channel or "Unknown",
            defender_argument=defender_raw,
            prosecutor_argument=prosecutor_raw,
            thumbnail_score=thumb_score,
            thumbnail_verdict=thumb_verdict,
            has_transcript=str(yt_data.has_transcript),
        )
        judge_raw  = await gemini_client.generate_with_pro(judge_prompt, response_key="youtube_judge")
        judge_data = _parse_judge(judge_raw)

        verdict    = judge_data.get("verdict", "UNCERTAIN").upper()
        if verdict not in {"AI_GENERATED", "HUMAN_CREATED", "UNCERTAIN"}:
            verdict = "UNCERTAIN"
        confidence = min(100, max(0, int(judge_data.get("confidence", 50))))
        summary    = judge_data.get("summary", "Analysis complete.")
        reasoning  = judge_data.get("reasoning", summary)

        logger.info(
            "YouTube pipeline complete: verdict=%s confidence=%d channel=%s",
            verdict, confidence, yt_data.channel,
        )

        return YouTubeResult(
            video_id=yt_data.video_id,
            title=yt_data.title,
            channel=yt_data.channel,
            verdict=verdict,
            confidence=confidence,
            summary=summary,
            ai_indicators=judge_data.get("ai_indicators", [])[:6],
            human_indicators=judge_data.get("human_indicators", [])[:6],
            thumbnail_is_ai=thumb_result.is_fake if thumb_result else False,
            thumbnail_confidence=thumb_result.confidence if thumb_result else 0.0,
            defender_argument=defender_argument,
            prosecutor_argument=prosecutor_argument,
            judge_reasoning=reasoning,
            has_transcript=yt_data.has_transcript,
        )


# Module-level singleton
youtube_pipeline = YouTubePipeline()
